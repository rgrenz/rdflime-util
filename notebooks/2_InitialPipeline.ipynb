{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74656ace",
   "metadata": {},
   "source": [
    "## Initial embedding pipeline\n",
    "Prerequisites:<br>\n",
    "DBpedia subset hosted with a SPARQL endpoint, metacritic-movies dataset cleaned in previous notebook.\n",
    "\n",
    "Purpose:<br>\n",
    "This pipeline builds knowledge graph embeddings for movie entities in the metacritic-movies dataset and trains a binary classifier to predict movie ratings (good/bad).\n",
    "\n",
    "(Hint)\n",
    "Make sure to select the poetry kernel. If it does not show up, try to reload your editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6525562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pyrdf2vec import RDF2VecTransformer\n",
    "from pyrdf2vec.embedders import Word2Vec\n",
    "from pyrdf2vec.graphs import KG\n",
    "from pyrdf2vec.walkers import RandomWalker\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from rdflimeConfig import dbpediaLocation, movieLocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd18d7e",
   "metadata": {},
   "source": [
    "### Initiate DBpedia and metacritic-movie datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc82a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikidata_URI15</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Release date</th>\n",
       "      <th>DBpedia_URI</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>DBpedia_URI15</th>\n",
       "      <th>YAGO_URI15</th>\n",
       "      <th>DBpedia_URI15_Base32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>http://www.wikidata.org/entity/Q83495</td>\n",
       "      <td>The Matrix</td>\n",
       "      <td>3/31/1999 0:00</td>\n",
       "      <td>http://dbpedia.org/resource/The_Matrix</td>\n",
       "      <td>good</td>\n",
       "      <td>1693</td>\n",
       "      <td>73</td>\n",
       "      <td>http://dbpedia.org/resource/The_Matrix</td>\n",
       "      <td>http://yago-knowledge.org/resource/The_Matrix</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>http://www.wikidata.org/entity/Q189600</td>\n",
       "      <td>The Matrix Reloaded</td>\n",
       "      <td>5/15/2003 0:00</td>\n",
       "      <td>http://dbpedia.org/resource/The_Matrix_Reloaded</td>\n",
       "      <td>good</td>\n",
       "      <td>755</td>\n",
       "      <td>62</td>\n",
       "      <td>http://dbpedia.org/resource/The_Matrix_Reloaded</td>\n",
       "      <td>http://yago-knowledge.org/resource/The_Matrix_...</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Wikidata_URI15                Movie  \\\n",
       "92     http://www.wikidata.org/entity/Q83495           The Matrix   \n",
       "1154  http://www.wikidata.org/entity/Q189600  The Matrix Reloaded   \n",
       "\n",
       "        Release date                                      DBpedia_URI label  \\\n",
       "92    3/31/1999 0:00           http://dbpedia.org/resource/The_Matrix  good   \n",
       "1154  5/15/2003 0:00  http://dbpedia.org/resource/The_Matrix_Reloaded  good   \n",
       "\n",
       "        id  rating                                    DBpedia_URI15  \\\n",
       "92    1693      73           http://dbpedia.org/resource/The_Matrix   \n",
       "1154   755      62  http://dbpedia.org/resource/The_Matrix_Reloaded   \n",
       "\n",
       "                                             YAGO_URI15  \\\n",
       "92        http://yago-knowledge.org/resource/The_Matrix   \n",
       "1154  http://yago-knowledge.org/resource/The_Matrix_...   \n",
       "\n",
       "                                   DBpedia_URI15_Base32  \n",
       "92    NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...  \n",
       "1154  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read movie dataset\n",
    "movieFull = pd.read_csv(os.path.join(movieLocation, \"movies_fixed.tsv\"), sep=\"\\t\")\n",
    "movieTrain = movieFull[400:]\n",
    "movieTest = movieFull[:400]\n",
    "movies = [movie.DBpedia_URI for index, movie in movieFull.iterrows()]\n",
    "\n",
    "# Check dataset structure\n",
    "movieFull[movieFull.DBpedia_URI.str.contains(\"Matrix\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654e869",
   "metadata": {},
   "source": [
    "### Build DBpedia embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a4af2",
   "metadata": {},
   "source": [
    "Train and store a PyRDF2Vec transformer with various parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaedf8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:58<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 967877 walks for 2000 entities (178.8813s)\n",
      "Fitted 967877 walks (33.0955s)\n",
      "0 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:07<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 967877 walks for 2000 entities (187.6276s)\n",
      "Fitted 967877 walks (37.3635s)\n",
      "0 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:20<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 967877 walks for 2000 entities (200.8808s)\n",
      "Fitted 967877 walks (52.4809s)\n",
      "1 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:29<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 967877 walks for 2000 entities (209.7185s)\n",
      "Fitted 967877 walks (89.9783s)\n",
      "1 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:28<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 967877 walks for 2000 entities (208.8070s)\n",
      "Fitted 967877 walks (105.5400s)\n",
      "1 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:22<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 967877 walks for 2000 entities (203.2874s)\n",
      "Fitted 967877 walks (151.5139s)\n"
     ]
    }
   ],
   "source": [
    "for algo in [0,1]: # 0: CBOW, 1: SG\n",
    "    for vsize in [50, 100, 200]: # Vector size of embeddings\n",
    "        print(algo, vsize)\n",
    "        \n",
    "        if os.path.exists(os.path.join(movieLocation, f\"rdf2vec_transformer_{'sg' if algo else 'cbow'}_{vsize}\")):\n",
    "            print(f\"Skipping transformer, as it already exists.\")\n",
    "            continue\n",
    "        \n",
    "        dbpedia = KG(dbpediaLocation, skip_verify=False, mul_req=False)\n",
    "        \n",
    "        transformer = RDF2VecTransformer(\n",
    "            Word2Vec(negative=25, sg=algo, vector_size=vsize),\n",
    "            walkers=[RandomWalker(max_walks=22, max_depth=2, with_reverse=True, n_jobs=8, md5_bytes=None)],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        walks = transformer.get_walks(dbpedia, movies[:])\n",
    "        transformer.fit(walks)\n",
    "        embeddings, literals = transformer.transform(dbpedia, movies[:])\n",
    "\n",
    "        targetPath = os.path.join(movieLocation, \"transformers\")\n",
    "        Path(targetPath).mkdir(parents=True, exist_ok=True)\n",
    "        transformer.save(os.path.join(targetPath, f\"rdf2vec_transformer_{'sg' if algo else 'cbow'}_{vsize}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f464e3f",
   "metadata": {},
   "source": [
    "### Store embeddings that are compatible to the Evaluation Framework\n",
    "In a next step, we would like to evaluate the quality of our generated embeddings. However, we first need to convert to a format that is readable by [GEval](https://github.com/mariaangelapellegrino/Evaluation-Framework), the graph embedding framework by Pellegrino et al.\n",
    "\n",
    "This entails two steps: First, apply the fixes from 1_DBpediaFixes.ipynb in reverse, i.e. \"unfix\" the IRIs to be compatible with the framework. Second, store the embeddings in the required CSV-like format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7b056ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(movieLocation, \"datasetFixes.json\"), \"r\") as f:\n",
    "    fixes = json.load(f)\n",
    "\n",
    "for algo in [\"cbow\", \"sg\"]:\n",
    "    for vsize in [50, 100, 200]: # Vector size of embeddings\n",
    "\n",
    "        with open(os.path.join(movieLocation, \"transformers\", f\"rdf2vec_transformer_{algo}_{vsize}\"), \"rb\") as file:\n",
    "            transformer: RDF2VecTransformer = pickle.load(file)\n",
    "\n",
    "        targetPath = os.path.join(movieLocation, \"embeddings\")\n",
    "        Path(targetPath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with open(os.path.join(targetPath, f\"embeddings_{algo}_{vsize}\"), \"w\") as file:\n",
    "            for index, embedding in enumerate(transformer._embeddings):\n",
    "\n",
    "                # \"Unfix\" IRI and replace with the version that the Evaluation Framework by Pellegrino et al. understands\n",
    "                movie = movies[index]\n",
    "                fix = next(filter(lambda f: f[\"fix\"] == movie, fixes), None)\n",
    "                if fix: movie = fix[\"original\"]            \n",
    "\n",
    "                # Write embedding to file\n",
    "                line = f\"{movie} {' '.join(map(str,embedding))}\\n\"\n",
    "                file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64077094",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331db838",
   "metadata": {},
   "source": [
    "### Learn final classifier on embeddings\n",
    "Testing with the framework by Pellegrino et al. (see below) reveals that SVC with C=100 delivers high accuracy on the given task (predicting movie quality). We therefore train and store such a classifier for every embedding variant that was trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff568210",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo in [0,1]: # 0: CBOW, 1: SG\n",
    "    for vsize in [50,100,200]: # Vector size of embeddings\n",
    "        \n",
    "        transformerPath = os.path.join(movieLocation, \"transformers\", f\"rdf2vec_transformer_{'sg' if algo else 'cbow'}_{vsize}\")\n",
    "        transformer = RDF2VecTransformer.load(transformerPath)\n",
    "\n",
    "        clf = SVC(C=100, probability=True)\n",
    "\n",
    "        # train-test split as seen in 0_MovieDataSetExploration.ipynb\n",
    "        clf.fit(transformer._embeddings[400:], movieTrain.label)\n",
    "\n",
    "        targetPath = os.path.join(movieLocation, \"classifiers\")\n",
    "        Path(targetPath).mkdir(parents=True, exist_ok=True)\n",
    "           \n",
    "        with open(os.path.join(targetPath, f\"svc_100_{'sg' if algo else 'cbow'}_{vsize}\" ), \"wb\") as file:\n",
    "            pickle.dump(clf, file)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b207f3",
   "metadata": {},
   "source": [
    "### Evaluation using Evaluation-Framework by Pellegrino et al.\n",
    "- Due to dependency conflicts, the evaluation cannot be run directly in this environment.\n",
    "- Instead use poetry to manage a separate environment for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cfdc38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalPath = os.path.join(movieLocation, \"embeddings\", \"evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97e8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# poetry add evaluation-framework\n",
    "from evaluation_framework.manager import FrameworkManager\n",
    "\n",
    "for algo in [\"cbow\", \"sg\"]:\n",
    "    for vsize in [50, 100, 200]: # Vector size of embeddings\n",
    "        p = os.path.join(movieLocation, f\"embeddings_{algo}_{vsize}\")\n",
    "\n",
    "        evaluation_manager = FrameworkManager()\n",
    "        evaluation_manager.evaluate(\n",
    "            p,\n",
    "            tasks=[\"Classification\"],\n",
    "            parallel=False,\n",
    "            debugging_mode=False,\n",
    "            vector_size=vsize,\n",
    "            result_directory_path=os.path.join(movieLocation, f\"embedding_evaluation_{algo}_{vsize}\")\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d31e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"comparison.csv\", sep=\" \")\n",
    "tab = pd.DataFrame()\n",
    "\n",
    "for algo in [\"cbow\", \"sg\"]:\n",
    "    for vsize in [50, 100, 200]:\n",
    "        r = results[results.test_name.str.contains(f\"{algo}_{vsize}\")] \\\n",
    "            .groupby(\"model\") \\\n",
    "            .max() \\\n",
    "            .reset_index()\n",
    "\n",
    "        row = {\"strategy\": f\"{algo}_{vsize}\"}\n",
    "        for m in [\"NB\", \"KNN\", \"SVM\", \"C45\"]:\n",
    "            row[m] = round(r[r.model==m].iloc[0][\"score_value\"]*100, 2)\n",
    "        tab = pd.concat([tab, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d127f",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf55ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "walks = transformer._walks\n",
    "\n",
    "print(f\"Number of entities with walks: {len(walks)}\")\n",
    "\n",
    "print(movies[0])\n",
    "print(f\"Walks per entity: {len(walks[0])}\")\n",
    "print(f\"First walk of first entity:\")\n",
    "print(walks[0][0])\n",
    "\n",
    "for walk in walks[1692]:\n",
    "    print(walk[0], walk[1], walk[2])\n",
    "\n",
    "# Distance(Matrix, Matrix Reloaded) < Distance(Matrix, The Batman)?\n",
    "# Can we represent the embeddings in a 2D space for visualization? -> See examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5178744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "# Reduce the dimensions of entity embeddings to represent them in a 2D plane.\n",
    "X_tsne = TSNE(random_state=42).fit_transform(transformer._embeddings[1600:])\n",
    "\n",
    "colors = list(map(lambda e: \"#00ff00\" if movieTest[movieTest.DBpedia_URI==e].iloc[0].label == \"good\" else \"#ff0000\", transformer._entities[1600:]))\n",
    "sizes = list(map(lambda e: abs(50-movieTest[movieTest.DBpedia_URI==e].iloc[0].rating)**2, transformer._entities[1600:]))\n",
    "\n",
    "# Ploy the embeddings of entities in a 2D plane, annotating them.\n",
    "f = plt.figure(figsize=(200, 80))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=colors, s=sizes)\n",
    "for x, y, t in zip(X_tsne[:, 0], X_tsne[:, 1], transformer._entities):\n",
    "    plt.annotate(t.split(\"/\")[-1], (x, y))\n",
    "\n",
    "# Display the graph with a title, removing the axes for better readability.\n",
    "plt.title(\"pyRDF2Vec\", fontsize=4)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "#f.savefig(\"figure.pdf\", bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc6f725a70bbe8041c097ab7eae8aeb625a2cc94c1af18b785b9d981852f3aec"
  },
  "kernelspec": {
   "display_name": "lime-kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
