{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74656ace",
   "metadata": {},
   "source": [
    "## Initial embedding pipeline\n",
    "Prerequisites:<br>\n",
    "DBpedia subset hosted with a SPARQL endpoint, relevant datasets (e.g. metacritic-movies) cleaned in previous notebook.\n",
    "\n",
    "Purpose:<br>\n",
    "This pipeline builds knowledge graph embeddings for entities of interest (e.g. movies) and trains a classifier to predict the target variable.\n",
    "\n",
    "(Hint)\n",
    "Make sure to select the poetry kernel. If it does not show up, try to reload your editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6525562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pyrdf2vec import RDF2VecTransformer\n",
    "from pyrdf2vec.embedders import Word2Vec\n",
    "from pyrdf2vec.graphs import KG\n",
    "from pyrdf2vec.walkers import RandomWalker\n",
    "from sklearn.svm import SVC\n",
    "from evaluation_framework.manager import FrameworkManager\n",
    "from rdflimeConfig import dbpediaLocation, datasets, load_dataset, split_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd18d7e",
   "metadata": {},
   "source": [
    "### Check datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc82a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikidata_URI15</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Release date</th>\n",
       "      <th>DBpedia_URI</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>DBpedia_URI15</th>\n",
       "      <th>YAGO_URI15</th>\n",
       "      <th>DBpedia_URI15_Base32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q238245</td>\n",
       "      <td>4 Months, 3 Weeks and 2 Days</td>\n",
       "      <td>1/23/2008 0:00</td>\n",
       "      <td>http://dbpedia.org/resource/4_Months,_3_Weeks_...</td>\n",
       "      <td>good</td>\n",
       "      <td>1601</td>\n",
       "      <td>97</td>\n",
       "      <td>http://dbpedia.org/resource/4_Months,_3_Weeks_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q170035</td>\n",
       "      <td>Ratatouille</td>\n",
       "      <td>6/29/2007 0:00</td>\n",
       "      <td>http://dbpedia.org/resource/Ratatouille_(film)</td>\n",
       "      <td>good</td>\n",
       "      <td>1602</td>\n",
       "      <td>96</td>\n",
       "      <td>http://dbpedia.org/resource/Ratatouille_(film)</td>\n",
       "      <td>http://yago-knowledge.org/resource/Ratatouille...</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1752684</td>\n",
       "      <td>Killer of Sheep</td>\n",
       "      <td>3/30/2007 0:00</td>\n",
       "      <td>http://dbpedia.org/resource/Killer_of_Sheep</td>\n",
       "      <td>good</td>\n",
       "      <td>1603</td>\n",
       "      <td>94</td>\n",
       "      <td>http://dbpedia.org/resource/Killer_of_Sheep</td>\n",
       "      <td>http://yago-knowledge.org/resource/Killer_of_S...</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Wikidata_URI15                         Movie  \\\n",
       "0   http://www.wikidata.org/entity/Q238245  4 Months, 3 Weeks and 2 Days   \n",
       "1   http://www.wikidata.org/entity/Q170035                   Ratatouille   \n",
       "2  http://www.wikidata.org/entity/Q1752684               Killer of Sheep   \n",
       "\n",
       "     Release date                                        DBpedia_URI label  \\\n",
       "0  1/23/2008 0:00  http://dbpedia.org/resource/4_Months,_3_Weeks_...  good   \n",
       "1  6/29/2007 0:00     http://dbpedia.org/resource/Ratatouille_(film)  good   \n",
       "2  3/30/2007 0:00        http://dbpedia.org/resource/Killer_of_Sheep  good   \n",
       "\n",
       "     id  rating                                      DBpedia_URI15  \\\n",
       "0  1601      97  http://dbpedia.org/resource/4_Months,_3_Weeks_...   \n",
       "1  1602      96     http://dbpedia.org/resource/Ratatouille_(film)   \n",
       "2  1603      94        http://dbpedia.org/resource/Killer_of_Sheep   \n",
       "\n",
       "                                          YAGO_URI15  \\\n",
       "0                                                NaN   \n",
       "1  http://yago-knowledge.org/resource/Ratatouille...   \n",
       "2  http://yago-knowledge.org/resource/Killer_of_S...   \n",
       "\n",
       "                                DBpedia_URI15_Base32  \n",
       "0  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6N...  \n",
       "1  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6U...  \n",
       "2  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6S...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikidata_URI15</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Release date</th>\n",
       "      <th>DBpedia_URI</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>DBpedia_URI15</th>\n",
       "      <th>YAGO_URI15</th>\n",
       "      <th>DBpedia_URI15_Base32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q238245</td>\n",
       "      <td>4 Months, 3 Weeks and 2 Days</td>\n",
       "      <td>1/23/2008 0:00</td>\n",
       "      <td>http://dbpedia.org/resource/4_Months,_3_Weeks_...</td>\n",
       "      <td>good</td>\n",
       "      <td>1601</td>\n",
       "      <td>97</td>\n",
       "      <td>http://dbpedia.org/resource/4_Months,_3_Weeks_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q170035</td>\n",
       "      <td>Ratatouille</td>\n",
       "      <td>6/29/2007 0:00</td>\n",
       "      <td>http://dbpedia.org/resource/Ratatouille_(film)</td>\n",
       "      <td>good</td>\n",
       "      <td>1602</td>\n",
       "      <td>96</td>\n",
       "      <td>http://dbpedia.org/resource/Ratatouille_(film)</td>\n",
       "      <td>http://yago-knowledge.org/resource/Ratatouille...</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1752684</td>\n",
       "      <td>Killer of Sheep</td>\n",
       "      <td>3/30/2007 0:00</td>\n",
       "      <td>http://dbpedia.org/resource/Killer_of_Sheep</td>\n",
       "      <td>good</td>\n",
       "      <td>1603</td>\n",
       "      <td>94</td>\n",
       "      <td>http://dbpedia.org/resource/Killer_of_Sheep</td>\n",
       "      <td>http://yago-knowledge.org/resource/Killer_of_S...</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Wikidata_URI15                         Movie  \\\n",
       "0   http://www.wikidata.org/entity/Q238245  4 Months, 3 Weeks and 2 Days   \n",
       "1   http://www.wikidata.org/entity/Q170035                   Ratatouille   \n",
       "2  http://www.wikidata.org/entity/Q1752684               Killer of Sheep   \n",
       "\n",
       "     Release date                                        DBpedia_URI label  \\\n",
       "0  1/23/2008 0:00  http://dbpedia.org/resource/4_Months,_3_Weeks_...  good   \n",
       "1  6/29/2007 0:00     http://dbpedia.org/resource/Ratatouille_(film)  good   \n",
       "2  3/30/2007 0:00        http://dbpedia.org/resource/Killer_of_Sheep  good   \n",
       "\n",
       "     id  rating                                      DBpedia_URI15  \\\n",
       "0  1601      97  http://dbpedia.org/resource/4_Months,_3_Weeks_...   \n",
       "1  1602      96     http://dbpedia.org/resource/Ratatouille_(film)   \n",
       "2  1603      94        http://dbpedia.org/resource/Killer_of_Sheep   \n",
       "\n",
       "                                          YAGO_URI15  \\\n",
       "0                                                NaN   \n",
       "1  http://yago-knowledge.org/resource/Ratatouille...   \n",
       "2  http://yago-knowledge.org/resource/Killer_of_S...   \n",
       "\n",
       "                                DBpedia_URI15_Base32  \n",
       "0  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6N...  \n",
       "1  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6U...  \n",
       "2  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6S...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for cfg in datasets:\n",
    "    dataset, entities = load_dataset(cfg)\n",
    "    display(dataset.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654e869",
   "metadata": {},
   "source": [
    "### Build DBpedia embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a4af2",
   "metadata": {},
   "source": [
    "Train and store a PyRDF2Vec transformer with various parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaedf8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:58<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 967877 walks for 2000 entities (178.8813s)\n",
      "Fitted 967877 walks (33.0955s)\n",
      "0 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:07<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 967877 walks for 2000 entities (187.6276s)\n",
      "Fitted 967877 walks (37.3635s)\n",
      "0 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:20<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 967877 walks for 2000 entities (200.8808s)\n",
      "Fitted 967877 walks (52.4809s)\n",
      "1 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:29<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 967877 walks for 2000 entities (209.7185s)\n",
      "Fitted 967877 walks (89.9783s)\n",
      "1 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:28<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 967877 walks for 2000 entities (208.8070s)\n",
      "Fitted 967877 walks (105.5400s)\n",
      "1 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [03:22<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 967877 walks for 2000 entities (203.2874s)\n",
      "Fitted 967877 walks (151.5139s)\n"
     ]
    }
   ],
   "source": [
    "for cfg in datasets:\n",
    "    for algo in [0,1]: # 0: CBOW, 1: SG\n",
    "        for vsize in [50, 100, 200]: # Vector size of embeddings\n",
    "            print(cfg[\"name\"], algo, vsize)\n",
    "\n",
    "            dataset, entities = load_dataset(cfg)\n",
    "            datasetLocation = cfg[\"location\"]\n",
    "            \n",
    "            if os.path.exists(os.path.join(datasetLocation, f\"rdf2vec_transformer_{'sg' if algo else 'cbow'}_{vsize}\")):\n",
    "                print(f\"Skipping transformer, as it already exists.\")\n",
    "                continue\n",
    "            \n",
    "            dbpedia = KG(dbpediaLocation, skip_verify=False, mul_req=False)\n",
    "            \n",
    "            transformer = RDF2VecTransformer(\n",
    "                Word2Vec(negative=25, sg=algo, vector_size=vsize),\n",
    "                walkers=[RandomWalker(max_walks=22, max_depth=2, with_reverse=True, n_jobs=8, md5_bytes=None)],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            walks = transformer.get_walks(dbpedia, entities)\n",
    "            transformer.fit(walks)\n",
    "            embeddings, literals = transformer.transform(dbpedia, entities)\n",
    "\n",
    "            targetPath = os.path.join(datasetLocation, \"transformers\")\n",
    "            Path(targetPath).mkdir(parents=True, exist_ok=True)\n",
    "            transformer.save(os.path.join(targetPath, f\"rdf2vec_transformer_{'sg' if algo else 'cbow'}_{vsize}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f464e3f",
   "metadata": {},
   "source": [
    "### Store embeddings that are compatible to the Evaluation Framework\n",
    "In a next step, we would like to evaluate the quality of our generated embeddings. However, we first need to convert to a format that is readable by [GEval](https://github.com/mariaangelapellegrino/Evaluation-Framework), the graph embedding framework by Pellegrino et al.\n",
    "\n",
    "This entails two steps: First, apply the fixes from 1_DBpediaFixes.ipynb in reverse, i.e. \"unfix\" the IRIs to be compatible with the framework. Second, store the embeddings in the required CSV-like format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7b056ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg in datasets:\n",
    "    datasetLocation = cfg[\"location\"]\n",
    "    _, entities = load_dataset(cfg)\n",
    "\n",
    "    with open(os.path.join(datasetLocation, \"datasetFixes.json\"), \"r\") as f:\n",
    "        fixes = json.load(f)\n",
    "\n",
    "    for algo in [\"cbow\", \"sg\"]:\n",
    "        for vsize in [50, 100, 200]: # Vector size of embeddings\n",
    "\n",
    "            with open(os.path.join(datasetLocation, \"transformers\", f\"rdf2vec_transformer_{algo}_{vsize}\"), \"rb\") as file:\n",
    "                transformer: RDF2VecTransformer = pickle.load(file)\n",
    "\n",
    "            targetPath = os.path.join(datasetLocation, \"embeddings\")\n",
    "            Path(targetPath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            with open(os.path.join(targetPath, f\"embeddings_{algo}_{vsize}\"), \"w\") as file:\n",
    "                for index, embedding in enumerate(transformer._embeddings):\n",
    "\n",
    "                    # \"Unfix\" IRI and replace with the version that the Evaluation Framework by Pellegrino et al. understands\n",
    "                    movie = entities[index]\n",
    "                    fix = next(filter(lambda f: f[\"fix\"] == movie, fixes), None)\n",
    "                    if fix: movie = fix[\"original\"]            \n",
    "\n",
    "                    # Write embedding to file\n",
    "                    line = f\"{movie} {' '.join(map(str,embedding))}\\n\"\n",
    "                    file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64077094",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b207f3",
   "metadata": {},
   "source": [
    "### Evaluation using Evaluation-Framework by Pellegrino et al.\n",
    "Load each of our embedding versions and run the classification task on the movie dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc5e727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start evaluation...\n",
      "Classification finished\n",
      "0:01:49\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:03:10\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:06:05\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:02:02\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:03:28\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:06:44\n"
     ]
    }
   ],
   "source": [
    "evalPath = os.path.join(movieLocation, \"embeddings\", \"evaluation\")\n",
    "Path(evalPath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for algo in [\"cbow\", \"sg\"]:\n",
    "    for vsize in [50, 100, 200]: # Vector size of embeddings\n",
    "        print(algo, vsize)\n",
    "\n",
    "        embeddingPath = os.path.join(movieLocation, \"embeddings\", f\"embeddings_{algo}_{vsize}\")\n",
    "        \n",
    "        evaluation_manager = FrameworkManager()\n",
    "        evaluation_manager.evaluate(\n",
    "            embeddingPath,\n",
    "            tasks=[\"Classification\"],\n",
    "            parallel=False,\n",
    "            debugging_mode=False,\n",
    "            vector_size=vsize,\n",
    "            result_directory_path=os.path.join(evalPath, f\"geval_result_{algo}_{vsize}\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f7281c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the results file to the proper location\n",
    "!mv comparison.csv $evalPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27d31e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>NB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM</th>\n",
       "      <th>C45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbow_50</td>\n",
       "      <td>75.35</td>\n",
       "      <td>80.64</td>\n",
       "      <td>86.04</td>\n",
       "      <td>67.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbow_100</td>\n",
       "      <td>77.65</td>\n",
       "      <td>81.15</td>\n",
       "      <td>89.29</td>\n",
       "      <td>68.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbow_200</td>\n",
       "      <td>76.88</td>\n",
       "      <td>83.17</td>\n",
       "      <td>91.04</td>\n",
       "      <td>68.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sg_50</td>\n",
       "      <td>69.76</td>\n",
       "      <td>72.28</td>\n",
       "      <td>78.82</td>\n",
       "      <td>57.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sg_100</td>\n",
       "      <td>70.90</td>\n",
       "      <td>73.66</td>\n",
       "      <td>83.78</td>\n",
       "      <td>57.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sg_200</td>\n",
       "      <td>71.42</td>\n",
       "      <td>72.53</td>\n",
       "      <td>85.70</td>\n",
       "      <td>57.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   strategy     NB    KNN    SVM    C45\n",
       "0   cbow_50  75.35  80.64  86.04  67.65\n",
       "1  cbow_100  77.65  81.15  89.29  68.20\n",
       "2  cbow_200  76.88  83.17  91.04  68.54\n",
       "3     sg_50  69.76  72.28  78.82  57.86\n",
       "4    sg_100  70.90  73.66  83.78  57.04\n",
       "5    sg_200  71.42  72.53  85.70  57.98"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(os.path.join(evalPath, \"comparison.csv\"), sep=\" \")\n",
    "tab = pd.DataFrame()\n",
    "\n",
    "for algo in [\"cbow\", \"sg\"]:\n",
    "    for vsize in [50, 100, 200]:\n",
    "        r = results[results.test_name.str.contains(f\"{algo}_{vsize}\")] \\\n",
    "            .groupby(\"model\") \\\n",
    "            .max() \\\n",
    "            .reset_index()\n",
    "\n",
    "        row = {\"strategy\": f\"{algo}_{vsize}\"}\n",
    "        for m in [\"NB\", \"KNN\", \"SVM\", \"C45\"]:\n",
    "            row[m] = round(r[r.model==m].iloc[0][\"score_value\"]*100, 2)\n",
    "        tab = pd.concat([tab, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331db838",
   "metadata": {},
   "source": [
    "### Learn final classifier on embeddings\n",
    "Testing with the framework by Pellegrino et al. (see above) reveals that SVC with C=100 delivers high accuracy on the given task (predicting movie quality). We therefore train and store such a classifier for every embedding variant that was trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff568210",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg in datasets:\n",
    "    for algo in [0,1]: # 0: CBOW, 1: SG\n",
    "        for vsize in [50,100,200]: # Vector size of embeddings\n",
    "\n",
    "            dataset, entities = load_dataset(cfg)\n",
    "            train, test = split_dataset(dataset, cfg)\n",
    "            datasetLocation = cfg[\"location\"]\n",
    "            label_col = cfg[\"columns\"][\"label\"]\n",
    "        \n",
    "            transformerPath = os.path.join(datasetLocation, \"transformers\", f\"rdf2vec_transformer_{'sg' if algo else 'cbow'}_{vsize}\")\n",
    "            transformer = RDF2VecTransformer.load(transformerPath)\n",
    "\n",
    "            clf = SVC(C=100, probability=True)\n",
    "\n",
    "            # train-test split as seen in 0_MovieDataSetExploration.ipynb\n",
    "            train_partition = cfg[\"train_partition\"]\n",
    "            clf.fit(transformer._embeddings[train_partition[0]:train_partition[1]], train[label_col])\n",
    "\n",
    "            targetPath = os.path.join(datasetLocation, \"classifiers\")\n",
    "            Path(targetPath).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            with open(os.path.join(targetPath, f\"svc_100_{'sg' if algo else 'cbow'}_{vsize}\" ), \"wb\") as file:\n",
    "                pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d127f",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf55ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities with walks: 2000\n",
      "Walks per entity: 484\n",
      "First walk of first entity:\n",
      "('http://dbpedia.org/resource/Category:Romanian_films_by_genre', 'http://www.w3.org/2004/02/skos/core#broader', 'http://dbpedia.org/resource/Category:Romanian_drama_films', 'http://purl.org/dc/terms/subject', 'http://dbpedia.org/resource/4_Months,_3_Weeks_and_2_Days', 'http://purl.org/dc/terms/subject', 'http://dbpedia.org/resource/Category:European_Film_Awards_winners_(films)', 'http://www.w3.org/2004/02/skos/core#prefLabel', 'European Film Awards winners (films)')\n"
     ]
    }
   ],
   "source": [
    "walks = transformer._walks\n",
    "\n",
    "print(f\"Number of entities with walks: {len(walks)}\")\n",
    "print(f\"Walks per entity: {len(walks[0])}\")\n",
    "print(f\"First walk of first entity:\")\n",
    "print(walks[0][0])\n",
    "\n",
    "# Distance(Matrix, Matrix Reloaded) < Distance(Matrix, The Batman)?\n",
    "# Can we represent the embeddings in a 2D space for visualization? -> See examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5178744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "transformer = RDF2VecTransformer.load(os.path.join(movieLocation, \"transformers\", \"rdf2vec_transformer_cbow_200\"))\n",
    "\n",
    "# Reduce the dimensions of entity embeddings to represent them in a 2D plane.\n",
    "X_tsne = TSNE(random_state=42).fit_transform(transformer._embeddings[:])\n",
    "\n",
    "colors = list(map(lambda e: \"#00ff00\" if movieFull[movieFull.DBpedia_URI==e].iloc[0].label == \"good\" else \"#ff0000\", transformer._entities[:]))\n",
    "sizes = list(map(lambda e: abs(50-movieFull[movieFull.DBpedia_URI==e].iloc[0].rating)**2, transformer._entities[:]))\n",
    "\n",
    "# Plot the embeddings of entities in a 2D plane, annotating them.\n",
    "f = plt.figure(figsize=(200, 80))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=colors, s=sizes)\n",
    "for x, y, t in zip(X_tsne[:, 0], X_tsne[:, 1], transformer._entities):\n",
    "    plt.annotate(t.split(\"/\")[-1], (x, y))\n",
    "\n",
    "# Display the graph with a title, removing the axes for better readability.\n",
    "plt.title(\"pyRDF2Vec\", fontsize=4)\n",
    "plt.axis(\"off\")\n",
    "#plt.show()\n",
    "\n",
    "f.savefig(os.path.join(movieLocation, \"figure.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6705c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce5a4af9a72a016c4887bc4fbd6c73d917f9c9f5d4de7f9550be99bde2950c61"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rdflime-util-cLuY5sAo-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
