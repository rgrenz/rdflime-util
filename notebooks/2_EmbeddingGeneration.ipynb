{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74656ace",
   "metadata": {},
   "source": [
    "## Initial embedding pipeline\n",
    "Prerequisites:<br>\n",
    "DBpedia subset hosted with a SPARQL endpoint, relevant datasets (e.g. metacritic-movies) cleaned in previous notebook.\n",
    "\n",
    "Purpose:<br>\n",
    "This pipeline builds knowledge graph embeddings for entities of interest (e.g. movies) and trains a classifier to predict the target variable.\n",
    "\n",
    "(Hint)\n",
    "Make sure to select the poetry kernel. If it does not show up, try to reload your editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6525562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pyrdf2vec import RDF2VecTransformer\n",
    "from pyrdf2vec.embedders import Word2Vec\n",
    "from pyrdf2vec.graphs import KG\n",
    "from pyrdf2vec.walkers import RandomWalker\n",
    "from sklearn.svm import SVC\n",
    "from evaluation_framework.manager import FrameworkManager\n",
    "from rdflimeConfig import dbpediaLocation, datasets, load_dataset, split_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd18d7e",
   "metadata": {},
   "source": [
    "### Check datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc82a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikidata_URI15</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Release date</th>\n",
       "      <th>DBpedia_URI</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>DBpedia_URI15</th>\n",
       "      <th>YAGO_URI15</th>\n",
       "      <th>DBpedia_URI15_Base32</th>\n",
       "      <th>DBpedia_URI16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q238245</td>\n",
       "      <td>4 Months, 3 Weeks and 2 Days</td>\n",
       "      <td>1/23/2008 0:00</td>\n",
       "      <td>http://dbpedia.org/resource/4_Months,_3_Weeks_...</td>\n",
       "      <td>good</td>\n",
       "      <td>1601</td>\n",
       "      <td>97</td>\n",
       "      <td>http://dbpedia.org/resource/4_Months,_3_Weeks_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6N...</td>\n",
       "      <td>http://dbpedia.org/resource/4_Months,_3_Weeks_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q170035</td>\n",
       "      <td>Ratatouille</td>\n",
       "      <td>6/29/2007 0:00</td>\n",
       "      <td>http://dbpedia.org/resource/Ratatouille_(film)</td>\n",
       "      <td>good</td>\n",
       "      <td>1602</td>\n",
       "      <td>96</td>\n",
       "      <td>http://dbpedia.org/resource/Ratatouille_(film)</td>\n",
       "      <td>http://yago-knowledge.org/resource/Ratatouille...</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6U...</td>\n",
       "      <td>http://dbpedia.org/resource/Ratatouille_(film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1752684</td>\n",
       "      <td>Killer of Sheep</td>\n",
       "      <td>3/30/2007 0:00</td>\n",
       "      <td>http://dbpedia.org/resource/Killer_of_Sheep</td>\n",
       "      <td>good</td>\n",
       "      <td>1603</td>\n",
       "      <td>94</td>\n",
       "      <td>http://dbpedia.org/resource/Killer_of_Sheep</td>\n",
       "      <td>http://yago-knowledge.org/resource/Killer_of_S...</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6S...</td>\n",
       "      <td>http://dbpedia.org/resource/Killer_of_Sheep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Wikidata_URI15                         Movie  \\\n",
       "0   http://www.wikidata.org/entity/Q238245  4 Months, 3 Weeks and 2 Days   \n",
       "1   http://www.wikidata.org/entity/Q170035                   Ratatouille   \n",
       "2  http://www.wikidata.org/entity/Q1752684               Killer of Sheep   \n",
       "\n",
       "     Release date                                        DBpedia_URI label  \\\n",
       "0  1/23/2008 0:00  http://dbpedia.org/resource/4_Months,_3_Weeks_...  good   \n",
       "1  6/29/2007 0:00     http://dbpedia.org/resource/Ratatouille_(film)  good   \n",
       "2  3/30/2007 0:00        http://dbpedia.org/resource/Killer_of_Sheep  good   \n",
       "\n",
       "     id  rating                                      DBpedia_URI15  \\\n",
       "0  1601      97  http://dbpedia.org/resource/4_Months,_3_Weeks_...   \n",
       "1  1602      96     http://dbpedia.org/resource/Ratatouille_(film)   \n",
       "2  1603      94        http://dbpedia.org/resource/Killer_of_Sheep   \n",
       "\n",
       "                                          YAGO_URI15  \\\n",
       "0                                                NaN   \n",
       "1  http://yago-knowledge.org/resource/Ratatouille...   \n",
       "2  http://yago-knowledge.org/resource/Killer_of_S...   \n",
       "\n",
       "                                DBpedia_URI15_Base32  \\\n",
       "0  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6N...   \n",
       "1  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6U...   \n",
       "2  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6S...   \n",
       "\n",
       "                                       DBpedia_URI16  \n",
       "0  http://dbpedia.org/resource/4_Months,_3_Weeks_...  \n",
       "1     http://dbpedia.org/resource/Ratatouille_(film)  \n",
       "2        http://dbpedia.org/resource/Killer_of_Sheep  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikidata_URI15</th>\n",
       "      <th>id</th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>DBpedia_URI</th>\n",
       "      <th>label</th>\n",
       "      <th>DBpedia_URI15</th>\n",
       "      <th>YAGO_URI15</th>\n",
       "      <th>DBpedia_URI15_Base32</th>\n",
       "      <th>DBpedia_URI16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q7913484</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Van Lear Rose</td>\n",
       "      <td>Loretta Lynn</td>\n",
       "      <td>27-Apr-04</td>\n",
       "      <td>97.0</td>\n",
       "      <td>http://dbpedia.org/resource/Van_Lear_Rose</td>\n",
       "      <td>good</td>\n",
       "      <td>http://dbpedia.org/resource/Van_Lear_Rose</td>\n",
       "      <td>http://yago-knowledge.org/resource/Van_Lear_Rose</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...</td>\n",
       "      <td>http://dbpedia.org/resource/Van_Lear_Rose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1036873</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Histoire de Melody Nelson</td>\n",
       "      <td>Serge Gainsbourg</td>\n",
       "      <td>24-Mar-09</td>\n",
       "      <td>96.0</td>\n",
       "      <td>http://dbpedia.org/resource/Histoire_de_Melody...</td>\n",
       "      <td>good</td>\n",
       "      <td>http://dbpedia.org/resource/Histoire_de_Melody...</td>\n",
       "      <td>http://yago-knowledge.org/resource/Histoire_de...</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6S...</td>\n",
       "      <td>http://dbpedia.org/resource/Histoire_de_Melody...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q378166</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stankonia</td>\n",
       "      <td>Outkast</td>\n",
       "      <td>31-Oct-00</td>\n",
       "      <td>95.0</td>\n",
       "      <td>http://dbpedia.org/resource/Stankonia</td>\n",
       "      <td>good</td>\n",
       "      <td>http://dbpedia.org/resource/Stankonia</td>\n",
       "      <td>http://yago-knowledge.org/resource/Stankonia</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6U...</td>\n",
       "      <td>http://dbpedia.org/resource/Stankonia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Wikidata_URI15   id                      album  \\\n",
       "0  http://www.wikidata.org/entity/Q7913484  1.0              Van Lear Rose   \n",
       "1  http://www.wikidata.org/entity/Q1036873  2.0  Histoire de Melody Nelson   \n",
       "2   http://www.wikidata.org/entity/Q378166  3.0                  Stankonia   \n",
       "\n",
       "             artist       date  rating  \\\n",
       "0      Loretta Lynn  27-Apr-04    97.0   \n",
       "1  Serge Gainsbourg  24-Mar-09    96.0   \n",
       "2           Outkast  31-Oct-00    95.0   \n",
       "\n",
       "                                         DBpedia_URI label  \\\n",
       "0          http://dbpedia.org/resource/Van_Lear_Rose  good   \n",
       "1  http://dbpedia.org/resource/Histoire_de_Melody...  good   \n",
       "2              http://dbpedia.org/resource/Stankonia  good   \n",
       "\n",
       "                                       DBpedia_URI15  \\\n",
       "0          http://dbpedia.org/resource/Van_Lear_Rose   \n",
       "1  http://dbpedia.org/resource/Histoire_de_Melody...   \n",
       "2              http://dbpedia.org/resource/Stankonia   \n",
       "\n",
       "                                          YAGO_URI15  \\\n",
       "0   http://yago-knowledge.org/resource/Van_Lear_Rose   \n",
       "1  http://yago-knowledge.org/resource/Histoire_de...   \n",
       "2       http://yago-knowledge.org/resource/Stankonia   \n",
       "\n",
       "                                DBpedia_URI15_Base32  \\\n",
       "0  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...   \n",
       "1  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6S...   \n",
       "2  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6U...   \n",
       "\n",
       "                                       DBpedia_URI16  \n",
       "0          http://dbpedia.org/resource/Van_Lear_Rose  \n",
       "1  http://dbpedia.org/resource/Histoire_de_Melody...  \n",
       "2              http://dbpedia.org/resource/Stankonia  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikidata_URI15</th>\n",
       "      <th>id</th>\n",
       "      <th>Company</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Country</th>\n",
       "      <th>rating</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Profits</th>\n",
       "      <th>Assets</th>\n",
       "      <th>Rank</th>\n",
       "      <th>DBpedia_URI</th>\n",
       "      <th>label</th>\n",
       "      <th>DBpedia_URI15</th>\n",
       "      <th>YAGO_URI15</th>\n",
       "      <th>DBpedia_URI15_Base32</th>\n",
       "      <th>DBpedia_URI16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q26463</td>\n",
       "      <td>1</td>\n",
       "      <td>Industrial and Commercial Bank of China</td>\n",
       "      <td>Major Banks</td>\n",
       "      <td>China</td>\n",
       "      <td>237.3</td>\n",
       "      <td>134.8</td>\n",
       "      <td>37.8</td>\n",
       "      <td>2813.5</td>\n",
       "      <td>1</td>\n",
       "      <td>http://dbpedia.org/resource/Industrial_and_Com...</td>\n",
       "      <td>high</td>\n",
       "      <td>http://dbpedia.org/resource/Industrial_and_Com...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6S...</td>\n",
       "      <td>http://dbpedia.org/resource/Industrial_and_Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q26299</td>\n",
       "      <td>2</td>\n",
       "      <td>China Construction Bank</td>\n",
       "      <td>Regional Banks</td>\n",
       "      <td>China</td>\n",
       "      <td>202.0</td>\n",
       "      <td>113.1</td>\n",
       "      <td>30.6</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>2</td>\n",
       "      <td>http://dbpedia.org/resource/China_Construction...</td>\n",
       "      <td>high</td>\n",
       "      <td>http://dbpedia.org/resource/China_Construction...</td>\n",
       "      <td>http://yago-knowledge.org/resource/China_Const...</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6Q...</td>\n",
       "      <td>http://dbpedia.org/resource/China_Construction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q192314</td>\n",
       "      <td>3</td>\n",
       "      <td>JPMorgan Chase</td>\n",
       "      <td>Major Banks</td>\n",
       "      <td>United States</td>\n",
       "      <td>191.4</td>\n",
       "      <td>108.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>2359.1</td>\n",
       "      <td>3</td>\n",
       "      <td>http://dbpedia.org/resource/JPMorgan_Chase</td>\n",
       "      <td>high</td>\n",
       "      <td>http://dbpedia.org/resource/JPMorgan_Chase</td>\n",
       "      <td>http://yago-knowledge.org/resource/JPMorgan_Chase</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6S...</td>\n",
       "      <td>http://dbpedia.org/resource/JPMorgan_Chase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Wikidata_URI15  id  \\\n",
       "0   http://www.wikidata.org/entity/Q26463   1   \n",
       "1   http://www.wikidata.org/entity/Q26299   2   \n",
       "2  http://www.wikidata.org/entity/Q192314   3   \n",
       "\n",
       "                                   Company        Industry        Country  \\\n",
       "0  Industrial and Commercial Bank of China     Major Banks          China   \n",
       "1                  China Construction Bank  Regional Banks          China   \n",
       "2                           JPMorgan Chase     Major Banks  United States   \n",
       "\n",
       "   rating  Sales  Profits  Assets  Rank  \\\n",
       "0   237.3  134.8     37.8  2813.5     1   \n",
       "1   202.0  113.1     30.6  2241.0     2   \n",
       "2   191.4  108.2     21.3  2359.1     3   \n",
       "\n",
       "                                         DBpedia_URI label  \\\n",
       "0  http://dbpedia.org/resource/Industrial_and_Com...  high   \n",
       "1  http://dbpedia.org/resource/China_Construction...  high   \n",
       "2         http://dbpedia.org/resource/JPMorgan_Chase  high   \n",
       "\n",
       "                                       DBpedia_URI15  \\\n",
       "0  http://dbpedia.org/resource/Industrial_and_Com...   \n",
       "1  http://dbpedia.org/resource/China_Construction...   \n",
       "2         http://dbpedia.org/resource/JPMorgan_Chase   \n",
       "\n",
       "                                          YAGO_URI15  \\\n",
       "0                                                NaN   \n",
       "1  http://yago-knowledge.org/resource/China_Const...   \n",
       "2  http://yago-knowledge.org/resource/JPMorgan_Chase   \n",
       "\n",
       "                                DBpedia_URI15_Base32  \\\n",
       "0  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6S...   \n",
       "1  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6Q...   \n",
       "2  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6S...   \n",
       "\n",
       "                                       DBpedia_URI16  \n",
       "0  http://dbpedia.org/resource/Industrial_and_Com...  \n",
       "1  http://dbpedia.org/resource/China_Construction...  \n",
       "2         http://dbpedia.org/resource/JPMorgan_Chase  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikidata_URI15</th>\n",
       "      <th>id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>DBpedia_URI</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>DBpedia_URI15</th>\n",
       "      <th>YAGO_URI15</th>\n",
       "      <th>DBpedia_URI15_Base32</th>\n",
       "      <th>DBpedia_URI16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q24639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>http://dbpedia.org/resource/Vancouver</td>\n",
       "      <td>106.0</td>\n",
       "      <td>high</td>\n",
       "      <td>http://dbpedia.org/resource/Vancouver</td>\n",
       "      <td>http://yago-knowledge.org/resource/Vancouver</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...</td>\n",
       "      <td>http://dbpedia.org/resource/Vancouver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>http://dbpedia.org/resource/Zurich</td>\n",
       "      <td>106.0</td>\n",
       "      <td>high</td>\n",
       "      <td>http://dbpedia.org/resource/Zürich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6W...</td>\n",
       "      <td>http://dbpedia.org/resource/Zürich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1741</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>http://dbpedia.org/resource/Vienna</td>\n",
       "      <td>106.0</td>\n",
       "      <td>high</td>\n",
       "      <td>http://dbpedia.org/resource/Vienna</td>\n",
       "      <td>http://yago-knowledge.org/resource/Vienna</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...</td>\n",
       "      <td>http://dbpedia.org/resource/Vienna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Wikidata_URI15   id  city_name  \\\n",
       "0  http://www.wikidata.org/entity/Q24639  1.0  Vancouver   \n",
       "1     http://www.wikidata.org/entity/Q72  2.0     Zurich   \n",
       "2   http://www.wikidata.org/entity/Q1741  3.0     Vienna   \n",
       "\n",
       "                             DBpedia_URI  rating label  \\\n",
       "0  http://dbpedia.org/resource/Vancouver   106.0  high   \n",
       "1     http://dbpedia.org/resource/Zurich   106.0  high   \n",
       "2     http://dbpedia.org/resource/Vienna   106.0  high   \n",
       "\n",
       "                           DBpedia_URI15  \\\n",
       "0  http://dbpedia.org/resource/Vancouver   \n",
       "1     http://dbpedia.org/resource/Zürich   \n",
       "2     http://dbpedia.org/resource/Vienna   \n",
       "\n",
       "                                     YAGO_URI15  \\\n",
       "0  http://yago-knowledge.org/resource/Vancouver   \n",
       "1                                           NaN   \n",
       "2     http://yago-knowledge.org/resource/Vienna   \n",
       "\n",
       "                                DBpedia_URI15_Base32  \\\n",
       "0  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...   \n",
       "1  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6W...   \n",
       "2  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...   \n",
       "\n",
       "                           DBpedia_URI16  \n",
       "0  http://dbpedia.org/resource/Vancouver  \n",
       "1     http://dbpedia.org/resource/Zürich  \n",
       "2     http://dbpedia.org/resource/Vienna  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikidata_URI15</th>\n",
       "      <th>FICE</th>\n",
       "      <th>College_name</th>\n",
       "      <th>State</th>\n",
       "      <th>Type</th>\n",
       "      <th>Average_salary_full_professors</th>\n",
       "      <th>Average_salary_associate_professors</th>\n",
       "      <th>Average_salary_assistant_professors</th>\n",
       "      <th>rating</th>\n",
       "      <th>Average_compensation_full_professor</th>\n",
       "      <th>...</th>\n",
       "      <th>Number_of_instructors</th>\n",
       "      <th>Number_of_faculty_all_ranks</th>\n",
       "      <th>DBpedia_URI</th>\n",
       "      <th>label</th>\n",
       "      <th>label_comp</th>\n",
       "      <th>id</th>\n",
       "      <th>DBpedia_URI15</th>\n",
       "      <th>YAGO_URI15</th>\n",
       "      <th>DBpedia_URI15_Base32</th>\n",
       "      <th>DBpedia_URI16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1565621</td>\n",
       "      <td>1061</td>\n",
       "      <td>Alaska Pacific University</td>\n",
       "      <td>AK</td>\n",
       "      <td>IIB</td>\n",
       "      <td>454</td>\n",
       "      <td>382</td>\n",
       "      <td>362.0</td>\n",
       "      <td>382</td>\n",
       "      <td>567</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>http://dbpedia.org/resource/Alaska_Pacific_Uni...</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "      <td>http://dbpedia.org/resource/Alaska_Pacific_Uni...</td>\n",
       "      <td>http://yago-knowledge.org/resource/Alaska_Paci...</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6Q...</td>\n",
       "      <td>http://dbpedia.org/resource/Alaska_Pacific_Uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1285262</td>\n",
       "      <td>1063</td>\n",
       "      <td>University of Alaska-Fairbanks</td>\n",
       "      <td>AK</td>\n",
       "      <td>I</td>\n",
       "      <td>686</td>\n",
       "      <td>560</td>\n",
       "      <td>432.0</td>\n",
       "      <td>508</td>\n",
       "      <td>914</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>404</td>\n",
       "      <td>http://dbpedia.org/resource/University_of_Alas...</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>http://dbpedia.org/resource/University_of_Alas...</td>\n",
       "      <td>http://yago-knowledge.org/resource/University_...</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...</td>\n",
       "      <td>http://dbpedia.org/resource/University_of_Alas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q94279</td>\n",
       "      <td>1065</td>\n",
       "      <td>University of Alaska-Southeast</td>\n",
       "      <td>AK</td>\n",
       "      <td>IIA</td>\n",
       "      <td>533</td>\n",
       "      <td>494</td>\n",
       "      <td>329.0</td>\n",
       "      <td>415</td>\n",
       "      <td>716</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>http://dbpedia.org/resource/University_of_Alas...</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>3</td>\n",
       "      <td>http://dbpedia.org/resource/University_of_Alas...</td>\n",
       "      <td>http://yago-knowledge.org/resource/University_...</td>\n",
       "      <td>NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...</td>\n",
       "      <td>http://dbpedia.org/resource/University_of_Alas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Wikidata_URI15  FICE  \\\n",
       "0  http://www.wikidata.org/entity/Q1565621  1061   \n",
       "1  http://www.wikidata.org/entity/Q1285262  1063   \n",
       "2    http://www.wikidata.org/entity/Q94279  1065   \n",
       "\n",
       "                     College_name State Type Average_salary_full_professors  \\\n",
       "0       Alaska Pacific University    AK  IIB                            454   \n",
       "1  University of Alaska-Fairbanks    AK    I                            686   \n",
       "2  University of Alaska-Southeast    AK  IIA                            533   \n",
       "\n",
       "  Average_salary_associate_professors  Average_salary_assistant_professors  \\\n",
       "0                                 382                                362.0   \n",
       "1                                 560                                432.0   \n",
       "2                                 494                                329.0   \n",
       "\n",
       "   rating Average_compensation_full_professor  ... Number_of_instructors  \\\n",
       "0     382                                 567  ...                     4   \n",
       "1     508                                 914  ...                    40   \n",
       "2     415                                 716  ...                     9   \n",
       "\n",
       "   Number_of_faculty_all_ranks  \\\n",
       "0                           32   \n",
       "1                          404   \n",
       "2                           70   \n",
       "\n",
       "                                         DBpedia_URI   label  label_comp  id  \\\n",
       "0  http://dbpedia.org/resource/Alaska_Pacific_Uni...  medium      medium   1   \n",
       "1  http://dbpedia.org/resource/University_of_Alas...    high        high   2   \n",
       "2  http://dbpedia.org/resource/University_of_Alas...  medium      medium   3   \n",
       "\n",
       "                                       DBpedia_URI15  \\\n",
       "0  http://dbpedia.org/resource/Alaska_Pacific_Uni...   \n",
       "1  http://dbpedia.org/resource/University_of_Alas...   \n",
       "2  http://dbpedia.org/resource/University_of_Alas...   \n",
       "\n",
       "                                          YAGO_URI15  \\\n",
       "0  http://yago-knowledge.org/resource/Alaska_Paci...   \n",
       "1  http://yago-knowledge.org/resource/University_...   \n",
       "2  http://yago-knowledge.org/resource/University_...   \n",
       "\n",
       "                                DBpedia_URI15_Base32  \\\n",
       "0  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6Q...   \n",
       "1  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...   \n",
       "2  NB2HI4B2F4XWIYTQMVSGSYJON5ZGOL3SMVZW65LSMNSS6V...   \n",
       "\n",
       "                                       DBpedia_URI16  \n",
       "0  http://dbpedia.org/resource/Alaska_Pacific_Uni...  \n",
       "1  http://dbpedia.org/resource/University_of_Alas...  \n",
       "2  http://dbpedia.org/resource/University_of_Alas...  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for cfg in datasets:\n",
    "    dataset, entities = load_dataset(cfg)\n",
    "    display(dataset.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654e869",
   "metadata": {},
   "source": [
    "### Build DBpedia embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a4af2",
   "metadata": {},
   "source": [
    "Train and store a PyRDF2Vec transformer with various parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaedf8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metacritic-movies 0 50\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m     \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1349\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/http/client.py:285\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line:\n\u001b[1;32m    283\u001b[0m     \u001b[39m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[39m# sending a valid response.\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mraise\u001b[39;00m RemoteDisconnected(\u001b[39m\"\u001b[39m\u001b[39mRemote end closed connection without\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39m response\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:785\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    783\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 785\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    786\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    787\u001b[0m )\n\u001b[1;32m    788\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/urllib3/util/retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 550\u001b[0m     \u001b[39mraise\u001b[39;00m six\u001b[39m.\u001b[39;49mreraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[1;32m    551\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/urllib3/packages/six.py:769\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[0;32m--> 769\u001b[0m     \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    770\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m     \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1349\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/http/client.py:285\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line:\n\u001b[1;32m    283\u001b[0m     \u001b[39m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[39m# sending a valid response.\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mraise\u001b[39;00m RemoteDisconnected(\u001b[39m\"\u001b[39m\u001b[39mRemote end closed connection without\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39m response\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=12'>13</a>\u001b[0m dbpedia \u001b[39m=\u001b[39m KG(dbpediaLocation, skip_verify\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, mul_req\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=14'>15</a>\u001b[0m transformer \u001b[39m=\u001b[39m RDF2VecTransformer(\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=15'>16</a>\u001b[0m     Word2Vec(sg\u001b[39m=\u001b[39malgo, vector_size\u001b[39m=\u001b[39mvsize), \u001b[39m# negative = 25\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=16'>17</a>\u001b[0m     walkers\u001b[39m=\u001b[39m[RandomWalker(max_walks\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, with_reverse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, n_jobs\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, md5_bytes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)], \u001b[39m# max_walks = 22, max_depth = 2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=17'>18</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=18'>19</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=20'>21</a>\u001b[0m walks \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mget_walks(dbpedia, entities)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=21'>22</a>\u001b[0m transformer\u001b[39m.\u001b[39mfit(walks)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=22'>23</a>\u001b[0m embeddings, literals \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mtransform(dbpedia, entities)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/pyrdf2vec/rdf2vec.py:163\u001b[0m, in \u001b[0;36mRDF2VecTransformer.get_walks\u001b[0;34m(self, kg, entities)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_walks\u001b[39m(\u001b[39mself\u001b[39m, kg: KG, entities: Entities) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[List[SWalk]]:\n\u001b[1;32m    147\u001b[0m     \u001b[39m\"\"\"Gets the walks of an entity based on a Knowledge Graph and a\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m    list of walkers\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m \n\u001b[1;32m    162\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mif\u001b[39;00m kg\u001b[39m.\u001b[39mskip_verify \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kg\u001b[39m.\u001b[39;49mis_exist(entities):\n\u001b[1;32m    164\u001b[0m         \u001b[39mif\u001b[39;00m kg\u001b[39m.\u001b[39mmul_req:\n\u001b[1;32m    165\u001b[0m             asyncio\u001b[39m.\u001b[39mrun(kg\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39mclose())\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/pyrdf2vec/graphs/kg.py:374\u001b[0m, in \u001b[0;36mKG.is_exist\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    369\u001b[0m     responses \u001b[39m=\u001b[39m [\n\u001b[1;32m    370\u001b[0m         res[\u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    371\u001b[0m         \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m asyncio\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39mafetch(queries))\n\u001b[1;32m    372\u001b[0m     ]\n\u001b[1;32m    373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     responses \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39mfetch(query) \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m queries]\n\u001b[1;32m    375\u001b[0m     responses \u001b[39m=\u001b[39m [res[\u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m responses]\n\u001b[1;32m    376\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m responses\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/pyrdf2vec/graphs/kg.py:374\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    369\u001b[0m     responses \u001b[39m=\u001b[39m [\n\u001b[1;32m    370\u001b[0m         res[\u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    371\u001b[0m         \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m asyncio\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39mafetch(queries))\n\u001b[1;32m    372\u001b[0m     ]\n\u001b[1;32m    373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     responses \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnector\u001b[39m.\u001b[39;49mfetch(query) \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m queries]\n\u001b[1;32m    375\u001b[0m     responses \u001b[39m=\u001b[39m [res[\u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m responses]\n\u001b[1;32m    376\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m responses\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/cachetools/__init__.py:567\u001b[0m, in \u001b[0;36mcachedmethod.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# key not found\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m v \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    568\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m     c[k] \u001b[39m=\u001b[39m v\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/pyrdf2vec/connectors.py:135\u001b[0m, in \u001b[0;36mSPARQLConnector.fetch\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39m\"\"\"Fetchs the result of a SPARQL query.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/query?query=\u001b[39m\u001b[39m{\u001b[39;00mparse\u001b[39m.\u001b[39mquote(query)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 135\u001b[0m \u001b[39mwith\u001b[39;00m requests\u001b[39m.\u001b[39;49mget(url, headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_headers) \u001b[39mas\u001b[39;00m res:\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/requests/adapters.py:547\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 547\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    549\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    550\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[1;32m    551\u001b[0m         \u001b[39m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "for cfg in datasets:\n",
    "    for algo in [0,1]: # 0: CBOW, 1: SG\n",
    "        for vsize in [50, 100, 200]: # Vector size of embeddings\n",
    "            print(cfg[\"name\"], algo, vsize)\n",
    "\n",
    "            dataset, entities = load_dataset(cfg)\n",
    "            datasetLocation = cfg[\"location\"]\n",
    "            \n",
    "            if os.path.exists(os.path.join(datasetLocation, f\"rdf2vec_transformer_{'sg' if algo else 'cbow'}_{vsize}\")):\n",
    "                print(f\"Skipping transformer, as it already exists.\")\n",
    "                continue\n",
    "            \n",
    "            dbpedia = KG(dbpediaLocation, skip_verify=False, mul_req=False)\n",
    "            \n",
    "            transformer = RDF2VecTransformer(\n",
    "                Word2Vec(sg=algo, vector_size=vsize), # negative = 25\n",
    "                walkers=[RandomWalker(max_walks=500, max_depth=4, with_reverse=False, n_jobs=8, md5_bytes=None)], # max_walks = 22, max_depth = 2\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            walks = transformer.get_walks(dbpedia, entities)\n",
    "            transformer.fit(walks)\n",
    "            embeddings, literals = transformer.transform(dbpedia, entities)\n",
    "\n",
    "            targetPath = os.path.join(datasetLocation, \"transformers\")\n",
    "            Path(targetPath).mkdir(parents=True, exist_ok=True)\n",
    "            transformer.save(os.path.join(targetPath, f\"rdf2vec_transformer_{'sg' if algo else 'cbow'}_{vsize}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f464e3f",
   "metadata": {},
   "source": [
    "### Store embeddings that are compatible to the Evaluation Framework\n",
    "In a next step, we would like to evaluate the quality of our generated embeddings. However, we first need to convert to a format that is readable by [GEval](https://github.com/mariaangelapellegrino/Evaluation-Framework), the graph embedding framework by Pellegrino et al.\n",
    "\n",
    "This entails two steps: First, apply the fixes from 1_DBpediaFixes.ipynb in reverse, i.e. \"unfix\" the IRIs to be compatible with the framework. Second, store the embeddings in the required CSV-like format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7b056ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg in datasets:\n",
    "    datasetLocation = cfg[\"location\"]\n",
    "    _, entities = load_dataset(cfg)\n",
    "\n",
    "    with open(os.path.join(datasetLocation, \"datasetFixes.json\"), \"r\") as f:\n",
    "        fixes = json.load(f)\n",
    "\n",
    "    for algo in [\"cbow\", \"sg\"]:\n",
    "        for vsize in [50, 100, 200]: # Vector size of embeddings\n",
    "\n",
    "            with open(os.path.join(datasetLocation, \"transformers\", f\"rdf2vec_transformer_{algo}_{vsize}\"), \"rb\") as file:\n",
    "                transformer: RDF2VecTransformer = pickle.load(file)\n",
    "\n",
    "            targetPath = os.path.join(datasetLocation, \"embeddings\")\n",
    "            Path(targetPath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            with open(os.path.join(targetPath, f\"embeddings_{algo}_{vsize}\"), \"w\") as file:\n",
    "                for index, embedding in enumerate(transformer._embeddings):\n",
    "\n",
    "                    # \"Unfix\" IRI and replace with the version that the Evaluation Framework by Pellegrino et al. understands\n",
    "                    movie = entities[index]\n",
    "                    fix = next(filter(lambda f: f[\"fix\"] == movie, fixes), None)\n",
    "                    if fix: movie = fix[\"original\"]            \n",
    "\n",
    "                    # Write embedding to file\n",
    "                    line = f\"{movie} {' '.join(map(str,embedding))}\\n\"\n",
    "                    file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64077094",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b207f3",
   "metadata": {},
   "source": [
    "### Evaluation using Evaluation-Framework by Pellegrino et al.\n",
    "Load each of our embedding versions and run the classification task on the movie dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc5e727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start evaluation...\n",
      "Classification finished\n",
      "0:01:49\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:03:10\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:06:05\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:02:02\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:03:28\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:06:44\n"
     ]
    }
   ],
   "source": [
    "evalPath = os.path.join(movieLocation, \"embeddings\", \"evaluation\")\n",
    "Path(evalPath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for algo in [\"cbow\", \"sg\"]:\n",
    "    for vsize in [50, 100, 200]: # Vector size of embeddings\n",
    "        print(algo, vsize)\n",
    "\n",
    "        embeddingPath = os.path.join(movieLocation, \"embeddings\", f\"embeddings_{algo}_{vsize}\")\n",
    "        \n",
    "        evaluation_manager = FrameworkManager()\n",
    "        evaluation_manager.evaluate(\n",
    "            embeddingPath,\n",
    "            tasks=[\"Classification\"],\n",
    "            parallel=False,\n",
    "            debugging_mode=False,\n",
    "            vector_size=vsize,\n",
    "            result_directory_path=os.path.join(evalPath, f\"geval_result_{algo}_{vsize}\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f7281c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the results file to the proper location\n",
    "!mv comparison.csv $evalPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27d31e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>NB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM</th>\n",
       "      <th>C45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbow_50</td>\n",
       "      <td>75.35</td>\n",
       "      <td>80.64</td>\n",
       "      <td>86.04</td>\n",
       "      <td>67.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbow_100</td>\n",
       "      <td>77.65</td>\n",
       "      <td>81.15</td>\n",
       "      <td>89.29</td>\n",
       "      <td>68.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbow_200</td>\n",
       "      <td>76.88</td>\n",
       "      <td>83.17</td>\n",
       "      <td>91.04</td>\n",
       "      <td>68.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sg_50</td>\n",
       "      <td>69.76</td>\n",
       "      <td>72.28</td>\n",
       "      <td>78.82</td>\n",
       "      <td>57.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sg_100</td>\n",
       "      <td>70.90</td>\n",
       "      <td>73.66</td>\n",
       "      <td>83.78</td>\n",
       "      <td>57.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sg_200</td>\n",
       "      <td>71.42</td>\n",
       "      <td>72.53</td>\n",
       "      <td>85.70</td>\n",
       "      <td>57.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   strategy     NB    KNN    SVM    C45\n",
       "0   cbow_50  75.35  80.64  86.04  67.65\n",
       "1  cbow_100  77.65  81.15  89.29  68.20\n",
       "2  cbow_200  76.88  83.17  91.04  68.54\n",
       "3     sg_50  69.76  72.28  78.82  57.86\n",
       "4    sg_100  70.90  73.66  83.78  57.04\n",
       "5    sg_200  71.42  72.53  85.70  57.98"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(os.path.join(evalPath, \"comparison.csv\"), sep=\" \")\n",
    "tab = pd.DataFrame()\n",
    "\n",
    "for algo in [\"cbow\", \"sg\"]:\n",
    "    for vsize in [50, 100, 200]:\n",
    "        r = results[results.test_name.str.contains(f\"{algo}_{vsize}\")] \\\n",
    "            .groupby(\"model\") \\\n",
    "            .max() \\\n",
    "            .reset_index()\n",
    "\n",
    "        row = {\"strategy\": f\"{algo}_{vsize}\"}\n",
    "        for m in [\"NB\", \"KNN\", \"SVM\", \"C45\"]:\n",
    "            row[m] = round(r[r.model==m].iloc[0][\"score_value\"]*100, 2)\n",
    "        tab = pd.concat([tab, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331db838",
   "metadata": {},
   "source": [
    "### Learn final classifier on embeddings\n",
    "Testing with the framework by Pellegrino et al. (see above) reveals that SVC with C=100 delivers high accuracy on the given task (predicting movie quality). We therefore train and store such a classifier for every embedding variant that was trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff568210",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg in datasets:\n",
    "    for algo in [0,1]: # 0: CBOW, 1: SG\n",
    "        for vsize in [50,100,200]: # Vector size of embeddings\n",
    "\n",
    "            dataset, entities = load_dataset(cfg)\n",
    "            train, test = split_dataset(dataset, cfg)\n",
    "            datasetLocation = cfg[\"location\"]\n",
    "            label_col = cfg[\"columns\"][\"label\"]\n",
    "        \n",
    "            transformerPath = os.path.join(datasetLocation, \"transformers\", f\"rdf2vec_transformer_{'sg' if algo else 'cbow'}_{vsize}\")\n",
    "            transformer = RDF2VecTransformer.load(transformerPath)\n",
    "\n",
    "            clf = SVC(C=100, probability=True)\n",
    "\n",
    "            # train-test split as seen in 0_MovieDataSetExploration.ipynb\n",
    "            train_partition = cfg[\"train_partition\"]\n",
    "            clf.fit(transformer._embeddings[train_partition[0]:train_partition[1]], train[label_col])\n",
    "\n",
    "            targetPath = os.path.join(datasetLocation, \"classifiers\")\n",
    "            Path(targetPath).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            with open(os.path.join(targetPath, f\"svc_100_{'sg' if algo else 'cbow'}_{vsize}\" ), \"wb\") as file:\n",
    "                pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d127f",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf55ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities with walks: 2000\n",
      "Walks per entity: 484\n",
      "First walk of first entity:\n",
      "('http://dbpedia.org/resource/Category:Romanian_films_by_genre', 'http://www.w3.org/2004/02/skos/core#broader', 'http://dbpedia.org/resource/Category:Romanian_drama_films', 'http://purl.org/dc/terms/subject', 'http://dbpedia.org/resource/4_Months,_3_Weeks_and_2_Days', 'http://purl.org/dc/terms/subject', 'http://dbpedia.org/resource/Category:European_Film_Awards_winners_(films)', 'http://www.w3.org/2004/02/skos/core#prefLabel', 'European Film Awards winners (films)')\n"
     ]
    }
   ],
   "source": [
    "walks = transformer._walks\n",
    "\n",
    "print(f\"Number of entities with walks: {len(walks)}\")\n",
    "print(f\"Walks per entity: {len(walks[0])}\")\n",
    "print(f\"First walk of first entity:\")\n",
    "print(walks[0][0])\n",
    "\n",
    "# Distance(Matrix, Matrix Reloaded) < Distance(Matrix, The Batman)?\n",
    "# Can we represent the embeddings in a 2D space for visualization? -> See examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5178744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "transformer = RDF2VecTransformer.load(os.path.join(movieLocation, \"transformers\", \"rdf2vec_transformer_cbow_200\"))\n",
    "\n",
    "# Reduce the dimensions of entity embeddings to represent them in a 2D plane.\n",
    "X_tsne = TSNE(random_state=42).fit_transform(transformer._embeddings[:])\n",
    "\n",
    "colors = list(map(lambda e: \"#00ff00\" if movieFull[movieFull.DBpedia_URI==e].iloc[0].label == \"good\" else \"#ff0000\", transformer._entities[:]))\n",
    "sizes = list(map(lambda e: abs(50-movieFull[movieFull.DBpedia_URI==e].iloc[0].rating)**2, transformer._entities[:]))\n",
    "\n",
    "# Plot the embeddings of entities in a 2D plane, annotating them.\n",
    "f = plt.figure(figsize=(200, 80))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=colors, s=sizes)\n",
    "for x, y, t in zip(X_tsne[:, 0], X_tsne[:, 1], transformer._entities):\n",
    "    plt.annotate(t.split(\"/\")[-1], (x, y))\n",
    "\n",
    "# Display the graph with a title, removing the axes for better readability.\n",
    "plt.title(\"pyRDF2Vec\", fontsize=4)\n",
    "plt.axis(\"off\")\n",
    "#plt.show()\n",
    "\n",
    "f.savefig(os.path.join(movieLocation, \"figure.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6705c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce5a4af9a72a016c4887bc4fbd6c73d917f9c9f5d4de7f9550be99bde2950c61"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rdflime-util-cLuY5sAo-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
