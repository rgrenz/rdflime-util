{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74656ace",
   "metadata": {},
   "source": [
    "## Initial embedding pipeline\n",
    "Prerequisites:<br>\n",
    "DBpedia subset hosted with a SPARQL endpoint, relevant datasets (e.g. metacritic-movies) cleaned in previous notebook.\n",
    "\n",
    "Purpose:<br>\n",
    "This pipeline builds knowledge graph embeddings for entities of interest (e.g. movies) and trains a classifier to predict the target variable.\n",
    "\n",
    "(Hint)\n",
    "Make sure to select the poetry kernel. If it does not show up, try to reload your editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6525562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pyrdf2vec import RDF2VecTransformer\n",
    "from pyrdf2vec.embedders import Word2Vec\n",
    "from pyrdf2vec.graphs import KG\n",
    "from pyrdf2vec.walkers import RandomWalker\n",
    "from sklearn.svm import SVC\n",
    "from evaluation_framework.manager import FrameworkManager\n",
    "from rdflimeConfig import dbpediaLocation, dataLocation, datasets, load_dataset, split_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654e869",
   "metadata": {},
   "source": [
    "### Build DBpedia embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a4af2",
   "metadata": {},
   "source": [
    "Train and store a PyRDF2Vec transformer with various parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaedf8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metacritic-movies 0 50\n",
      "Skipping transformer, as it already exists.\n",
      "metacritic-movies 0 100\n",
      "Skipping transformer, as it already exists.\n",
      "metacritic-movies 0 200\n",
      "Skipping transformer, as it already exists.\n",
      "metacritic-movies 1 50\n",
      "Skipping transformer, as it already exists.\n",
      "metacritic-movies 1 100\n",
      "Skipping transformer, as it already exists.\n",
      "metacritic-movies 1 200\n",
      "Skipping transformer, as it already exists.\n",
      "metacritic-albums 0 50\n",
      "Skipping transformer, as it already exists.\n",
      "metacritic-albums 0 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=14'>15</a>\u001b[0m dbpedia \u001b[39m=\u001b[39m KG(dbpediaLocation, skip_verify\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, mul_req\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=16'>17</a>\u001b[0m transformer \u001b[39m=\u001b[39m RDF2VecTransformer(\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=17'>18</a>\u001b[0m     Word2Vec(sg\u001b[39m=\u001b[39malgo, vector_size\u001b[39m=\u001b[39mvsize), \u001b[39m# negative = 25\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=18'>19</a>\u001b[0m     walkers\u001b[39m=\u001b[39m[RandomWalker(max_walks\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, with_reverse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, n_jobs\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, md5_bytes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)], \u001b[39m# max_walks = 22, max_depth = 2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=19'>20</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=20'>21</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=22'>23</a>\u001b[0m walks \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mget_walks(dbpedia, entities)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=23'>24</a>\u001b[0m transformer\u001b[39m.\u001b[39mfit(walks)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000006vscode-remote?line=24'>25</a>\u001b[0m embeddings, literals \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mtransform(dbpedia, entities)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/pyrdf2vec/rdf2vec.py:163\u001b[0m, in \u001b[0;36mRDF2VecTransformer.get_walks\u001b[0;34m(self, kg, entities)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_walks\u001b[39m(\u001b[39mself\u001b[39m, kg: KG, entities: Entities) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[List[SWalk]]:\n\u001b[1;32m    147\u001b[0m     \u001b[39m\"\"\"Gets the walks of an entity based on a Knowledge Graph and a\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m    list of walkers\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m \n\u001b[1;32m    162\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mif\u001b[39;00m kg\u001b[39m.\u001b[39mskip_verify \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kg\u001b[39m.\u001b[39;49mis_exist(entities):\n\u001b[1;32m    164\u001b[0m         \u001b[39mif\u001b[39;00m kg\u001b[39m.\u001b[39mmul_req:\n\u001b[1;32m    165\u001b[0m             asyncio\u001b[39m.\u001b[39mrun(kg\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39mclose())\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/pyrdf2vec/graphs/kg.py:374\u001b[0m, in \u001b[0;36mKG.is_exist\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    369\u001b[0m     responses \u001b[39m=\u001b[39m [\n\u001b[1;32m    370\u001b[0m         res[\u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    371\u001b[0m         \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m asyncio\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39mafetch(queries))\n\u001b[1;32m    372\u001b[0m     ]\n\u001b[1;32m    373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     responses \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39mfetch(query) \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m queries]\n\u001b[1;32m    375\u001b[0m     responses \u001b[39m=\u001b[39m [res[\u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m responses]\n\u001b[1;32m    376\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m responses\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/pyrdf2vec/graphs/kg.py:374\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    369\u001b[0m     responses \u001b[39m=\u001b[39m [\n\u001b[1;32m    370\u001b[0m         res[\u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    371\u001b[0m         \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m asyncio\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39mafetch(queries))\n\u001b[1;32m    372\u001b[0m     ]\n\u001b[1;32m    373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     responses \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnector\u001b[39m.\u001b[39;49mfetch(query) \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m queries]\n\u001b[1;32m    375\u001b[0m     responses \u001b[39m=\u001b[39m [res[\u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m responses]\n\u001b[1;32m    376\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m responses\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/cachetools/__init__.py:567\u001b[0m, in \u001b[0;36mcachedmethod.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# key not found\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m v \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    568\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m     c[k] \u001b[39m=\u001b[39m v\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/pyrdf2vec/connectors.py:135\u001b[0m, in \u001b[0;36mSPARQLConnector.fetch\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39m\"\"\"Fetchs the result of a SPARQL query.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/query?query=\u001b[39m\u001b[39m{\u001b[39;00mparse\u001b[39m.\u001b[39mquote(query)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 135\u001b[0m \u001b[39mwith\u001b[39;00m requests\u001b[39m.\u001b[39;49mget(url, headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_headers) \u001b[39mas\u001b[39;00m res:\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1349\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1350\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for cfg in datasets:\n",
    "    for algo in [0,1]: # 0: CBOW, 1: SG\n",
    "        for vsize in [50, 100, 200]: # Vector size of embeddings\n",
    "            print(cfg[\"name\"], algo, vsize)\n",
    "\n",
    "            dataset, entities = load_dataset(cfg)\n",
    "            datasetLocation = cfg[\"location\"]\n",
    "            \n",
    "            targetPath = os.path.join(datasetLocation, \"transformers\")\n",
    "            targetFile = f\"rdf2vec_transformer_{'sg' if algo else 'cbow'}_{vsize}\"\n",
    "            if os.path.exists(os.path.join(targetPath, targetFile)):\n",
    "                print(f\"Skipping transformer, as it already exists.\")\n",
    "                continue\n",
    "            \n",
    "            dbpedia = KG(dbpediaLocation, skip_verify=False, mul_req=False)\n",
    "            \n",
    "            transformer = RDF2VecTransformer(\n",
    "                Word2Vec(sg=algo, vector_size=vsize), # negative = 25\n",
    "                walkers=[RandomWalker(max_walks=1, max_depth=4, with_reverse=False, n_jobs=2, md5_bytes=None)], # max_walks = 22, max_depth = 2\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            walks = transformer.get_walks(dbpedia, entities)\n",
    "            transformer.fit(walks)\n",
    "            embeddings, literals = transformer.transform(dbpedia, entities)\n",
    "\n",
    "            Path(targetPath).mkdir(parents=True, exist_ok=True)\n",
    "            transformer.save(os.path.join(targetPath, targetFile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f464e3f",
   "metadata": {},
   "source": [
    "### Store embeddings that are compatible to the Evaluation Framework\n",
    "In a next step, we would like to evaluate the quality of our generated embeddings. However, we first need to convert to a format that is readable by [GEval](https://github.com/mariaangelapellegrino/Evaluation-Framework), the graph embedding framework by Pellegrino et al.\n",
    "\n",
    "This entails two steps: First, apply the fixes from 1_DBpediaFixes.ipynb in reverse, i.e. \"unfix\" the IRIs to be compatible with the framework. Second, store the embeddings in the required CSV-like format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b056ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/metacritic-albums/transformers/rdf2vec_transformer_cbow_100'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000008vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m algo \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcbow\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msg\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000008vscode-remote?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m vsize \u001b[39min\u001b[39;00m [\u001b[39m50\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m200\u001b[39m]: \u001b[39m# Vector size of embeddings\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000008vscode-remote?line=7'>8</a>\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(datasetLocation, \u001b[39m\"\u001b[39;49m\u001b[39mtransformers\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrdf2vec_transformer_\u001b[39;49m\u001b[39m{\u001b[39;49;00malgo\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mvsize\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000008vscode-remote?line=8'>9</a>\u001b[0m             transformer: RDF2VecTransformer \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(file)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000008vscode-remote?line=10'>11</a>\u001b[0m         targetPath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(datasetLocation, \u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/metacritic-albums/transformers/rdf2vec_transformer_cbow_100'"
     ]
    }
   ],
   "source": [
    "for cfg in datasets:\n",
    "    datasetLocation = cfg[\"location\"]\n",
    "    dataset, entities = load_dataset(cfg)\n",
    "\n",
    "    for algo in [\"cbow\", \"sg\"]:\n",
    "        for vsize in [50, 100, 200]: # Vector size of embeddings\n",
    "\n",
    "            with open(os.path.join(datasetLocation, \"transformers\", f\"rdf2vec_transformer_{algo}_{vsize}\"), \"rb\") as file:\n",
    "                transformer: RDF2VecTransformer = pickle.load(file)\n",
    "\n",
    "            targetPath = os.path.join(datasetLocation, \"..\", \"embeddings\")\n",
    "            Path(targetPath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            with open(os.path.join(targetPath, f\"embeddings_{algo}_{vsize}\"), \"a\") as file:\n",
    "                for index, embedding in enumerate(transformer._embeddings):\n",
    "\n",
    "                    # \"Unfix\" IRI and replace with the version that the Evaluation Framework by Pellegrino et al. understands\n",
    "                    entity = entities[index]\n",
    "                    entity = dataset[dataset[cfg[\"columns\"][\"uri_fixed\"]] == entity][cfg[\"columns\"][\"uri_geval\"]].iloc[0].replace(\" \", \"+\")        \n",
    "\n",
    "                    # Write embedding to file\n",
    "                    line = f\"{entity} {' '.join(map(str,embedding))}\\n\"\n",
    "                    file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64077094",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b207f3",
   "metadata": {},
   "source": [
    "### Evaluation using Evaluation-Framework by Pellegrino et al.\n",
    "Load each of our embedding versions and run the classification task on the movie dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc5e727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow 50\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:02:51\n",
      "cbow 100\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:02:18\n",
      "cbow 200\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:04:23\n",
      "sg 50\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:01:30\n",
      "sg 100\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:02:40\n",
      "sg 200\n",
      "Start evaluation...\n",
      "Classification finished\n",
      "0:05:07\n"
     ]
    }
   ],
   "source": [
    "evalPath = os.path.join(dataLocation, \"embeddings\", \"evaluation\")\n",
    "Path(evalPath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for algo in [\"cbow\", \"sg\"]:\n",
    "    for vsize in [50, 100, 200]: # Vector size of embeddings\n",
    "        print(algo, vsize)\n",
    "\n",
    "        embeddingPath = os.path.join(dataLocation, \"embeddings\", f\"embeddings_{algo}_{vsize}\")\n",
    "        \n",
    "        evaluation_manager = FrameworkManager()\n",
    "        evaluation_manager.evaluate(\n",
    "            embeddingPath,\n",
    "            tasks=[\"Classification\"],\n",
    "            parallel=False,\n",
    "            debugging_mode=False,\n",
    "            vector_size=vsize,\n",
    "            result_directory_path=os.path.join(evalPath, f\"geval_result_{algo}_{vsize}\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f7281c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the results file to the proper location\n",
    "!mv comparison.csv $evalPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27d31e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>NB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM</th>\n",
       "      <th>C45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbow_50</td>\n",
       "      <td>77.02</td>\n",
       "      <td>86.37</td>\n",
       "      <td>93.54</td>\n",
       "      <td>75.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbow_100</td>\n",
       "      <td>75.66</td>\n",
       "      <td>89.40</td>\n",
       "      <td>94.97</td>\n",
       "      <td>79.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbow_200</td>\n",
       "      <td>76.85</td>\n",
       "      <td>89.69</td>\n",
       "      <td>95.44</td>\n",
       "      <td>81.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sg_50</td>\n",
       "      <td>82.76</td>\n",
       "      <td>81.44</td>\n",
       "      <td>87.96</td>\n",
       "      <td>72.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sg_100</td>\n",
       "      <td>82.55</td>\n",
       "      <td>81.90</td>\n",
       "      <td>91.64</td>\n",
       "      <td>70.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sg_200</td>\n",
       "      <td>82.33</td>\n",
       "      <td>82.28</td>\n",
       "      <td>92.88</td>\n",
       "      <td>71.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   strategy     NB    KNN    SVM    C45\n",
       "0   cbow_50  77.02  86.37  93.54  75.39\n",
       "1  cbow_100  75.66  89.40  94.97  79.61\n",
       "2  cbow_200  76.85  89.69  95.44  81.45\n",
       "3     sg_50  82.76  81.44  87.96  72.92\n",
       "4    sg_100  82.55  81.90  91.64  70.99\n",
       "5    sg_200  82.33  82.28  92.88  71.76"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(os.path.join(evalPath, \"comparison.csv\"), sep=\" \")\n",
    "tab = pd.DataFrame()\n",
    "\n",
    "for algo in [\"cbow\", \"sg\"]:\n",
    "    for vsize in [50, 100, 200]:\n",
    "        r = results[results.test_name.str.contains(f\"{algo}_{vsize}\")] \\\n",
    "            .groupby(\"model\") \\\n",
    "            .max() \\\n",
    "            .reset_index()\n",
    "\n",
    "        row = {\"strategy\": f\"{algo}_{vsize}\"}\n",
    "        for m in [\"NB\", \"KNN\", \"SVM\", \"C45\"]:\n",
    "            row[m] = round(r[r.model==m].iloc[0][\"score_value\"]*100, 2)\n",
    "        tab = pd.concat([tab, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331db838",
   "metadata": {},
   "source": [
    "### Learn final classifier on embeddings\n",
    "Testing with the framework by Pellegrino et al. (see above) reveals that SVC with C=100 delivers high accuracy on the given task (predicting movie quality). We therefore train and store such a classifier for every embedding variant that was trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff568210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metacritic-movies 0 50\n",
      "0.97\n",
      "metacritic-movies 0 100\n",
      "0.95\n",
      "metacritic-movies 0 200\n",
      "0.965\n",
      "metacritic-movies 1 50\n",
      "0.95\n",
      "metacritic-movies 1 100\n",
      "0.925\n",
      "metacritic-movies 1 200\n",
      "0.92\n",
      "metacritic-albums 0 50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1392, 1400]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000011vscode-remote?line=15'>16</a>\u001b[0m \u001b[39m# train-test split as seen in 0_MovieDataSetExploration.ipynb\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000011vscode-remote?line=16'>17</a>\u001b[0m train_partition \u001b[39m=\u001b[39m cfg[\u001b[39m\"\u001b[39m\u001b[39mtrain_partition\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000011vscode-remote?line=17'>18</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(transformer\u001b[39m.\u001b[39;49m_embeddings[\u001b[39m200\u001b[39;49m:\u001b[39m1800\u001b[39;49m], dataset[\u001b[39m200\u001b[39;49m:\u001b[39m1800\u001b[39;49m][label_col]) \u001b[39m#test[label_col])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000011vscode-remote?line=19'>20</a>\u001b[0m test_partition \u001b[39m=\u001b[39m cfg[\u001b[39m\"\u001b[39m\u001b[39mtest_partition\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B5c5c77736c2e6c6f63616c686f73745c44656269616e5c686f6d655c726f7576656e5c776f726b5c756e696d615c7264666c696d65/workspaces/rdflime/rdflime-util/notebooks/2_EmbeddingGeneration.ipynb#ch0000011vscode-remote?line=20'>21</a>\u001b[0m pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(transformer\u001b[39m.\u001b[39m_embeddings[\u001b[39m1800\u001b[39m:])\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:160\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    158\u001b[0m     check_consistent_length(X, y)\n\u001b[1;32m    159\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    161\u001b[0m                                order\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m'\u001b[39;49m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    162\u001b[0m                                accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    164\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_targets(y)\n\u001b[1;32m    166\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray([]\n\u001b[1;32m    167\u001b[0m                            \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    168\u001b[0m                            \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/sklearn/base.py:432\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    433\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:73\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mPass \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m as keyword args. From version 0.25 \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mpassing these as positional arguments will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mresult in an error\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(args_msg)),\n\u001b[1;32m     71\u001b[0m                   \u001b[39mFutureWarning\u001b[39;00m)\n\u001b[1;32m     72\u001b[0m kwargs\u001b[39m.\u001b[39mupdate({k: arg \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:813\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mif\u001b[39;00m y_numeric \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mO\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    811\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m--> 813\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m    815\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdflime-util-cLuY5sAo-py3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:256\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    255\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths])\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1392, 1400]"
     ]
    }
   ],
   "source": [
    "for cfg in datasets:\n",
    "    for algo in [0,1]: # 0: CBOW, 1: SG\n",
    "        for vsize in [50,100,200]: # Vector size of embeddings\n",
    "\n",
    "            print(cfg[\"name\"], algo, vsize)\n",
    "            dataset, entities = load_dataset(cfg)\n",
    "            train, test = split_dataset(dataset, cfg)\n",
    "            datasetLocation = cfg[\"location\"]\n",
    "            label_col = cfg[\"columns\"][\"label\"]\n",
    "        \n",
    "            transformerPath = os.path.join(datasetLocation, \"transformers\", f\"rdf2vec_transformer_{'sg' if algo else 'cbow'}_{vsize}\")\n",
    "            transformer = RDF2VecTransformer.load(transformerPath)\n",
    "\n",
    "            clf = SVC(C=100, probability=True)\n",
    "\n",
    "            # train-test split as seen in 0_MovieDataSetExploration.ipynb\n",
    "            train_partition = cfg[\"train_partition\"]\n",
    "            clf.fit(transformer._embeddings[200:1800], dataset[200:1800][label_col]) #test[label_col])\n",
    "\n",
    "            test_partition = cfg[\"test_partition\"]\n",
    "            pred = clf.predict(transformer._embeddings[1800:])\n",
    "\n",
    "            from sklearn.metrics import accuracy_score\n",
    "            s = accuracy_score(dataset[1800:][label_col], pred)\n",
    "            print(s)\n",
    "\n",
    "\n",
    "            targetPath = os.path.join(datasetLocation, \"classifiers\")\n",
    "            Path(targetPath).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            with open(os.path.join(targetPath, f\"svc_100_{'sg' if algo else 'cbow'}_{vsize}\" ), \"wb\") as file:\n",
    "                pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d127f",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf55ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities with walks: 2000\n",
      "Walks per entity: 484\n",
      "First walk of first entity:\n",
      "('http://dbpedia.org/resource/Category:Romanian_films_by_genre', 'http://www.w3.org/2004/02/skos/core#broader', 'http://dbpedia.org/resource/Category:Romanian_drama_films', 'http://purl.org/dc/terms/subject', 'http://dbpedia.org/resource/4_Months,_3_Weeks_and_2_Days', 'http://purl.org/dc/terms/subject', 'http://dbpedia.org/resource/Category:European_Film_Awards_winners_(films)', 'http://www.w3.org/2004/02/skos/core#prefLabel', 'European Film Awards winners (films)')\n"
     ]
    }
   ],
   "source": [
    "walks = transformer._walks\n",
    "\n",
    "print(f\"Number of entities with walks: {len(walks)}\")\n",
    "print(f\"Walks per entity: {len(walks[0])}\")\n",
    "print(f\"First walk of first entity:\")\n",
    "print(walks[0][0])\n",
    "\n",
    "# Distance(Matrix, Matrix Reloaded) < Distance(Matrix, The Batman)?\n",
    "# Can we represent the embeddings in a 2D space for visualization? -> See examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5178744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "transformer = RDF2VecTransformer.load(os.path.join(movieLocation, \"transformers\", \"rdf2vec_transformer_cbow_200\"))\n",
    "\n",
    "# Reduce the dimensions of entity embeddings to represent them in a 2D plane.\n",
    "X_tsne = TSNE(random_state=42).fit_transform(transformer._embeddings[:])\n",
    "\n",
    "colors = list(map(lambda e: \"#00ff00\" if movieFull[movieFull.DBpedia_URI==e].iloc[0].label == \"good\" else \"#ff0000\", transformer._entities[:]))\n",
    "sizes = list(map(lambda e: abs(50-movieFull[movieFull.DBpedia_URI==e].iloc[0].rating)**2, transformer._entities[:]))\n",
    "\n",
    "# Plot the embeddings of entities in a 2D plane, annotating them.\n",
    "f = plt.figure(figsize=(200, 80))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=colors, s=sizes)\n",
    "for x, y, t in zip(X_tsne[:, 0], X_tsne[:, 1], transformer._entities):\n",
    "    plt.annotate(t.split(\"/\")[-1], (x, y))\n",
    "\n",
    "# Display the graph with a title, removing the axes for better readability.\n",
    "plt.title(\"pyRDF2Vec\", fontsize=4)\n",
    "plt.axis(\"off\")\n",
    "#plt.show()\n",
    "\n",
    "f.savefig(os.path.join(movieLocation, \"figure.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6705c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce5a4af9a72a016c4887bc4fbd6c73d917f9c9f5d4de7f9550be99bde2950c61"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rdflime-util-cLuY5sAo-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
